name: Universal AI Code Review

on:
  push:
    branches: [ main, master, development ]
  pull_request:
    branches: [ main, master, development ]

jobs:
  ai-code-review:
    runs-on: ubuntu-latest
    
    env:
      OLLAMA_HOST: http://localhost:11434
      REVIEW_CATEGORIES: |
        # Advanced Code Analysis Pre-Prompt
        ## Primary Analysis Parameters
        Perform a comprehensive static and dynamic code analysis with the following focus areas:
        ### 1. Metric Collection
        - Calculate cyclomatic complexity for each function
        - Measure Halstead complexity metrics
        - Generate maintainability index
        - Count effective lines of code (eLOC)
        - Assess comment-to-code ratio
        - Identify duplicate code segments (with >3 lines)
        ### 2. Variable and Resource Analysis
        - Track variable lifecycle and usage patterns
        - Identify unused or redundant variables
        - Detect memory leaks and resource management issues
        - Analyze scope contamination
        - Check for proper initialization
        ### 3. Control Flow Analysis
        - Map execution paths
        - Identify unreachable code
        - Detect infinite loops
        - Analyze exception handling paths
        - Evaluate branching complexity
        ### 4. Data Flow Analysis
        - Track data transformations
        - Identify potential null references
        - Check for uninitialized variables
        - Analyze type consistency
        - Evaluate thread safety
        ### 5. Security Assessment
        - Check for common vulnerability patterns
        - Analyze input validation
        - Evaluate output encoding
        - Assess authentication mechanisms
        - Review authorization controls
        ### 6. Performance Profiling
        - Calculate algorithmic complexity
        - Identify performance bottlenecks
        - Analyze memory usage patterns
        - Evaluate I/O operations
        - Check resource utilization
        ### 7. Code Style and Standards
        - Verify naming conventions
        - Check formatting consistency
        - Assess documentation quality
        - Evaluate code organization
        - Review error handling practices
        ## Output Format Requirements
        Generate a structured analysis report including:
        1. Executive Summary
           - Overall code quality score (0-100)
           - Critical issues count
           - High-priority recommendations
           - Technical debt assessment
        2. Detailed Metrics
           - Complexity scores
           - Quality metrics
           - Performance indicators
           - Security ratings
        3. Issue Analysis
           - Categorized problems
           - Root cause analysis
           - Impact assessment
           - Resolution priority
        4. Recommendations
           - Specific refactoring suggestions
           - Optimization opportunities
           - Security improvements
           - Best practice alignment
        5. Visualization Data
           - Complexity trends
           - Issue distribution
           - Quality metrics
           - Performance patterns
        ## Special Considerations
        - Identify language-specific idioms and patterns
        - Consider framework-specific best practices
        - Evaluate cloud-native compatibility
        - Assess microservices architecture alignment
        - Review API design principles
    
    steps:
    # Rest of the workflow remains the same
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install Ollama
      run: |
        curl -fsSL https://ollama.com/install.sh | sh
        
        # Start Ollama service
        ollama serve &
        
        # Wait for Ollama to be fully operational
        for i in {1..30}; do
          if curl -s http://localhost:11434/api/health >/dev/null; then
            echo "âœ“ Ollama is running"
            break
          fi
          echo "Waiting for Ollama to start..."
          sleep 2
        done
    
    - name: Pull and Verify Llama Model
      run: |
        ollama pull llama3.2:latest
        # Verify model is pulled correctly
        ollama list | grep llama3.2
    
    - name: Install Python Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests flask flask-cors
    
    - name: Create Review Script
      run: |
        cat > review_code.py << 'EOF'
        import os
        import requests
        import json
        import traceback
        from flask import Flask, request, jsonify
        from threading import Thread
        import time

        app = Flask(__name__)

        @app.route('/api/review', methods=['POST'])
        def review_code():
            try:
                data = request.json
                code = data['code']
                filename = data['fileName']
                
                # Prepare prompt for code review
                prompt = f"""Please review the following code from {filename}. 
                
                {os.getenv('REVIEW_CATEGORIES')}
                
                Here's the code to review:
                
                {code}
                """
                
                # Send to local Ollama
                response = requests.post(
                    f"{os.getenv('OLLAMA_HOST')}/api/generate",
                    json={
                        "model": "llama3.2:latest",
                        "prompt": prompt,
                        "stream": False
                    }
                )
                
                if response.status_code == 200:
                    review_text = response.json()['response']
                    return jsonify({
                        'fileName': filename,
                        'reviewResults': {
                            'comprehensive_review': review_text
                        }
                    })
                else:
                    return jsonify({'error': 'Failed to get review from Ollama'}), 500
                    
            except Exception as e:
                return jsonify({'error': str(e), 'traceback': traceback.format_exc()}), 500

        def run_flask():
            app.run(host='0.0.0.0', port=5000)

        if __name__ == '__main__':
            flask_thread = Thread(target=run_flask)
            flask_thread.start()
            print("Flask server started")
        EOF
    
    - name: Start Review Server
      run: |
        python review_code.py &
        echo "Waiting for server to start..."
        sleep 5
        
        # Verify server is running
        if curl -s http://localhost:5000/api/review -X POST -H "Content-Type: application/json" -d '{"code":"test","fileName":"test.py"}' > /dev/null; then
          echo "âœ“ Review server is operational"
        else
          echo "Ã— Failed to verify review server"
          exit 1
        fi
    
    - name: Run Code Review
      run: |
        mkdir -p code-reviews
        
        python3 << 'EOF'
        import os
        import requests
        import json
        
        def is_source_file(path):
            source_extensions = [
                '.py', '.js', '.jsx', '.ts', '.tsx', 
                '.java', '.cpp', '.c', '.rb', '.go', 
                '.php', '.swift', '.kt', '.rs', 
                '.html', '.css', '.scss', '.lua'
            ]
            return any(path.endswith(ext) for ext in source_extensions)
        
        def should_exclude(path):
            exclude_dirs = [
                '.git', 'node_modules', 'dist', 'build', 
                'venv', '.venv', 'env', '.env', 
                'coverage', 'logs', '__pycache__'
            ]
            return any(exclude in path.split(os.path.sep) for exclude in exclude_dirs)
        
        def review_file(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    code = f.read()
                
                response = requests.post(
                    'http://localhost:5000/api/review',
                    json={'code': code, 'fileName': os.path.basename(file_path)},
                    timeout=300
                )
                
                if response.status_code == 200:
                    return response.json()
                else:
                    print(f"Error reviewing {file_path}: {response.text}")
                return None
            except Exception as e:
                print(f"Exception reviewing {file_path}: {str(e)}")
                return None
        
        def generate_report(reviews):
            report = "# ðŸ¤– AI Code Review Report\n\n"
            
            if not reviews:
                report += "No files were reviewed.\n"
                return report
                
            report += f"## Overview\n\n**Files Reviewed:** {len(reviews)}\n\n"
            
            for review in reviews:
                if not review:
                    continue
                    
                filename = review.get('fileName', 'Unknown File')
                review_results = review.get('reviewResults', {})
                comprehensive_review = review_results.get('comprehensive_review', '')
                
                report += f"## File: `{filename}`\n\n"
                report += f"### Review\n\n{comprehensive_review}\n\n"
                report += "---\n\n"
            
            return report
        
        # Main review process
        reviews = []
        for root, _, files in os.walk('.'):
            for file in files:
                full_path = os.path.join(root, file)
                
                if should_exclude(full_path) or not is_source_file(full_path):
                    continue
                
                print(f"Reviewing: {full_path}")
                review = review_file(full_path)
                if review:
                    reviews.append(review)
        
        # Generate and save report
        report = generate_report(reviews)
        with open('code-reviews/review_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("Review completed. Report generated at code-reviews/review_report.md")
        EOF
    
    - name: Commit Review Results
      run: |
        git config user.name github-actions
        git config user.email github-actions@github.com
        git add code-reviews/review_report.md || true
        git commit -m "Add AI Code Review Report [skip ci]" || true
        git push || true
